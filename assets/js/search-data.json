{
  
    
        "post0": {
            "title": "Patchwork",
            "content": "You exist as an idea of your mind. . – Shunryu Suzuki . After these first pretty boring posts let&#39;s do something a bit more interesting. A while ago I stumbled over . COCO-GAN:Generation by Parts via Conditional Coordinating https://hubert0527.github.io/COCO-GAN/ . The main idea behind this Generative Adverserial Network is to generate images of human faces not directly in their entirety yet as the title suggests by parts. . Inspired by this insteresting idea, let&#39;s create one building block of such a GAN by writing Tensorflow Layers which . decompose an image into parts | compose these parts into a single image again | . Getting ready . import numpy as np import tensorflow as tf from matplotlib import pyplot as plt from IPython import display image_path = &#39;./images/sunflower.jpg&#39; . Preprocessing the image . Loading the image file into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL Image instance to a Numpy array: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | Determining the height and width of the image. . | Converting the single image into a batch. (Keras layers are expecting a batch as input.) . | image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) height,width,_ = image_np_array.shape #(3) image_np_array_batch = np.array([image_np_array]) #(4) print(&quot;Image numpy array shape: {}&quot;.format(image_np_array.shape)) . Image numpy array shape: (1080, 1080, 3) . The original image . plt.figure(figsize=(12,12)) plt.title(&#39;Original Image&#39;) plt.imshow(image_np_array/255.0) plt.show() print(&quot; nImage height/width: {}/{} n&quot;.format(height,width)) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T20:49:06.767793 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Image height/width: 1080/1080 . The Magic . ... to be explained ... . class Patchwork(tf.keras.layers.Layer): def __init__(self, image_shape, tile_size, image_to_patches=True): super(Patchwork, self).__init__(dtype=&#39;float32&#39;) self.image_shape = image_shape self.tile_size = tile_size self.image_to_patches = image_to_patches self.patch_factor = ( self.image_shape[0]//self.tile_size[0]) * (self.image_shape[1]//self.tile_size[1]) def call(self, input): if self.image_to_patches: batch_size = tf.shape(input)[0] x = tf.reshape(input, [ batch_size, self.image_shape[0], -1, self.tile_size[1], self.image_shape[2]]) x = tf.transpose(x, [0, 2, 1, 3, 4]) return tf.reshape(x, [-1, self.tile_size[0], self.tile_size[1], self.image_shape[2]]) else: result_batch_size = tf.shape(input)[0] / self.patch_factor x = tf.reshape(input, [ result_batch_size, -1, self.image_shape[0], self.tile_size[1], self.image_shape[2]]) x = tf.transpose(x, [0, 2, 1, 3, 4]) return tf.reshape( x, [-1, self.image_shape[0], self.image_shape[1], self.image_shape[2]]) . Decomposing the image . image_shape = image_np_array.shape patch_shape = (image_shape[0]//2,image_shape[1]//2) image_to_patches_layer = Patchwork(image_shape,patch_shape) patches = image_to_patches_layer(image_np_array_batch) . The glorious result . f, axarr = plt.subplots(2,2) f.set_figheight(12) f.set_figwidth(12) for idx, image_np_array in enumerate(patches): row = idx // 2 col = idx % 2 axarr[col,row].imshow(image_np_array/255.) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T21:03:06.942057 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Composing the original images from the parts . patches_to_image_layer = Patchwork(image_shape,patch_shape,False) reunited_image = patches_to_image_layer(patches) plt.figure(figsize=(12,12)) plt.title(&#39;Reunited Image&#39;) plt.imshow(reunited_image[0]/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T20:54:15.234971 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Let&#39;s play . flipped_patches = np.flip(patches,0) flipped_patches_image = patches_to_image_layer(flipped_patches) plt.figure(figsize=(12,12)) plt.title(&#39;Image with flipped patches&#39;) plt.imshow(flipped_patches_image[0]/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T20:56:28.809025 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/",
            "url": "https://dorjeduck.github.io/ai-candies/2020/10/31/patchwork.html",
            "relUrl": "/2020/10/31/patchwork.html",
            "date": " • Oct 31, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Image Flip Layer",
            "content": "Mirror facing mirror - nowhere else. . – Ikkyu . In this tutorial we will create our first custom Keras layer which flips the input images horizontal. . Getting ready . import numpy as np import os import tensorflow as tf from matplotlib import pyplot as plt from IPython import display image_paths = [] image_paths.append(&#39;./images/espresso_1.jpg&#39;) image_paths.append(&#39;./images/espresso_2.jpg&#39;) . Preprocessing the images . Loading the two image files into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL image instances into Numpy arrays: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | image_np_arries = [] for image_path in image_paths: image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) image_np_arries.append(image_np_array) image_np_array_batch = np.array(image_np_arries) . The original images . for idx, image_np_array in enumerate(image_np_array_batch): plt.figure(figsize=(12,12)) plt.title(os.path.basename(image_paths[idx])) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T18:10:43.823761 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T18:10:44.367276 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Our custom Keras layer . For a thorough explanation on custom layers (and models) see: . https://www.tensorflow.org/guide/keras/custom_layers_and_models . class HorizontalFlip(tf.keras.layers.Layer): def __init__(self): super(HorizontalFlip, self).__init__() def call(self, inputs): return tf.image.flip_left_right(inputs) . Flipping the images . horizontal_flip = HorizontalFlip() image_flipped_np_array_batch = horizontal_flip(image_np_array_batch) . The glorious result . for idx, image_np_array in enumerate(image_flipped_np_array_batch): plt.figure(figsize=(12,12)) plt.title(&quot;flipped {}&quot;.format(os.path.basename(image_paths[idx]))) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T18:10:45.822297 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T18:10:46.356201 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/",
            "url": "https://dorjeduck.github.io/ai-candies/2020/10/26/image-flip-layer.html",
            "relUrl": "/2020/10/26/image-flip-layer.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Image cropping",
            "content": "Swim out of your little pond. . – Rumi . In this short tutorial we will see one way of cropping the central portion of two images to a given target height and width with the use of a Keras layer. It is important to notice that the two images have to be of the same height and width in order to be able to crop them togther in one batch. . Getting ready . import numpy as np import os import tensorflow as tf from matplotlib import pyplot as plt from IPython import display target_height = 200 target_width = 800 image_paths = [] image_paths.append(&#39;./images/boot_ganga_1.jpg&#39;) image_paths.append(&#39;./images/boot_ganga_2.jpg&#39;) . Preprocessing the images . Loading the two image files into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL image instancea to Numpy arrays: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | image_np_arries = [] for image_path in image_paths: image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) image_np_arries.append(image_np_array) height, width, _ = image_np_array.shape print(&quot;height/width of {} : {}/{}&quot;.format(os.path.basename(image_path),image_np_array.shape[0],image_np_array.shape[1])) image_np_array_batch = np.array(image_np_arries) . height/width of boot_ganga_1.jpg : 800/1200 height/width of boot_ganga_2.jpg : 800/1200 . The original images . for idx, image_np_array in enumerate(image_np_array_batch): plt.figure(figsize=(12,12)) plt.title(os.path.basename(image_paths[idx])) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:29.613095 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:30.036683 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cropping the images . 1) Creating a CenterCrop layer for given target height and width. https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CenterCrop . 2) Cropping the images . center_crop_layer = tf.keras.layers.experimental.preprocessing.CenterCrop(target_height,target_width) #(1) image_cropped_np_array_batch = center_crop_layer(image_np_array_batch) #(2) print(&quot;Keras CenterCrop Layer output shape (Numpy Array): {}&quot;.format(image_cropped_np_array_batch.shape)) . Keras CenterCrop Layer output shape (Numpy Array): (2, 200, 800, 3) . The glorious result . for idx, image_cropped_np_array in enumerate(image_cropped_np_array_batch): plt.figure(figsize=(8,8)) plt.title(&quot;resized {}&quot;.format(os.path.basename(image_paths[idx]))) plt.imshow(image_cropped_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:31.261107 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:31.435318 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/",
            "url": "https://dorjeduck.github.io/ai-candies/2020/10/26/image-center-crop.html",
            "relUrl": "/2020/10/26/image-center-crop.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Resizing an image with a Keras Layer",
            "content": "Out real nature is infinite in scope. . – Mingyur Rinpoche . First post, everyone welcome. As a start we will use a Keras Layer to resize an image. Sounds doable but do we need a deep learning library like Keras/Tensorflow for that? No. Yet this blog is about learning the building blocks for complex neural networks. . Enjoy . Getting ready . import numpy as np import tensorflow as tf from matplotlib import pyplot as plt from IPython import display image_path = &#39;./images/fujiyama.png&#39; . Preprocessing the image . Loading the image file into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL Image instance to a Numpy array: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | Determining the height and width of the image. . | Converting the single image into a batch. (Keras layers are expecting a batch as input.) . | image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) height,width,_ = image_np_array.shape #(3) image_np_array_batch = np.array([image_np_array]) #(4) print(&quot;Image numpy array shape: {}&quot;.format(image_np_array.shape)) . Image numpy array shape: (1024, 1536, 3) . The original image . plt.figure(figsize=(12,12)) plt.title(&#39;Original Image&#39;) plt.imshow(image_np_array/255.0) plt.show() print(&quot; nImage height/width: {}/{} n&quot;.format(height,width)) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:54.511012 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Image height/width: 1024/1536 . Resizing the image . 1) Creating an Image resizing layer for given target height &amp; width with Keras https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Resizing . 2) Resizing the image . height_resized = height // 2 width_resized = width // 2 print(&quot;Desired target image height/width: {}/{}&quot;.format(height_resized,width_resized)) resize_layer = tf.keras.layers.experimental.preprocessing.Resizing(height_resized,width_resized,interpolation=&#39;bilinear&#39;) #(1) image_resized_np_array_batch = resize_layer(image_np_array_batch) #(2) print(&quot;Keras Resizing Layer output shape (Numpy Array): {}&quot;.format(image_resized_np_array_batch.shape)) . Desired target image height/width: 512/768 Keras Resizing Layer output shape (Numpy Array): (1, 512, 768, 3) . The glorious result . image_resized_np_array = image_resized_np_array_batch[0] height_resized,width_resized,_ = image_resized_np_array.shape plt.figure(figsize=(6,6)) plt.title(&#39;Resized Image&#39;) plt.imshow(image_resized_np_array/255.0) plt.show() print(&quot; nResized image height/width: {}/{} n&quot;.format(height_resized,width_resized)) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:55.248885 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Resized image height/width: 512/768 .",
            "url": "https://dorjeduck.github.io/ai-candies/2020/10/25/image-resizing.html",
            "relUrl": "/2020/10/25/image-resizing.html",
            "date": " • Oct 25, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Hello visual world",
          "content": "I study my mind and therefore all appearances are my texts. . – Milarepa . This blog is driven by the idea to teach myself how to process and generate images with Tensorflow. The initial posts will mostly cover basic techniques which hopefully come in handy years later when I start trying to impress myself with more complex models based on these earlier insights. . Please feel invited to come along with me on this journey. I will try to include links to the respective parts of the excellent Tensorflow documentation or other gems on the web as much as possible in order to make this whole endeavour at least of some benefit. . As always, feedback and suggestions of any kind are highly appreciated. .",
          "url": "https://dorjeduck.github.io/ai-candies/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://dorjeduck.github.io/ai-candies/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}