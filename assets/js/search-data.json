{
  
    
        "post0": {
            "title": "Don't be mean",
            "content": "My true religion is kindness. . – The 14th Dalai Lama . In this short post we will see how to the calcuate the pixel wise mean over a collection of images. For this we implement a simple custom Keras Layer which combines each given number of images within the input batch by calculating the mean of the images. . Getting ready . import numpy as np import tensorflow as tf from matplotlib import pyplot as plt from IPython import display image_paths = [] image_paths.append(&#39;./images/lovecoffee.jpg&#39;) image_paths.append(&#39;./images/lovekillscapitalism.jpg&#39;) image_paths.append(&#39;./images/light_1.jpg&#39;) image_paths.append(&#39;./images/light_2.jpg&#39;) . Preprocessing the images . Loading the two image files into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL image instancea to Numpy arrays: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | image_np_arries = [] for image_path in image_paths: image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) image_np_arries.append(image_np_array) image_np_array_batch = np.array(image_np_arries) . The original images . for idx, image_np_array in enumerate(image_np_array_batch): plt.figure(figsize=(12,12)) plt.title(os.path.basename(image_paths[idx])) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-01T16:15:12.335492 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-01T16:15:12.879561 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Calculating the mean images . As we believe in the good of human kind we assume for the sake of simplicity that the length of the input batch is a multiple of the given images_per_mean parameter. . class ImagesMean(tf.keras.layers.Layer): def __init__(self,images_per_mean): super(ImagesMean, self).__init__() self.images_per_mean = images_per_mean def call(self,input): x = tf.reshape(input,[-1,self.images_per_mean,input.shape[1],input.shape[2],input.shape[3]]) return tf.math.reduce_mean(x,axis = 1) images_mean_layer = ImagesMean(2) image_mean = images_mean_layer(image_np_array_batch) . for image_np_array in image_mean_batch: plt.figure(figsize=(12,12)) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-01T15:37:01.752896 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/",
            "url": "https://dorjeduck.github.io/ai-candies/2020/11/01/dont-be-mean.html",
            "relUrl": "/2020/11/01/dont-be-mean.html",
            "date": " • Nov 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Patchwork",
            "content": "You exist as an idea of your mind. . – Shunryu Suzuki . After these first pretty boring posts let&#39;s do something a bit more interesting. A while ago I stumbled over . COCO-GAN:Generation by Parts via Conditional Coordinating https://hubert0527.github.io/COCO-GAN/ . The main idea behind this Generative Adverserial Network is to generate images of human faces not directly in their entirety yet as the title suggests by parts. . Inspired by this interesting idea, let&#39;s create one building block of such a GAN by writing Tensorflow Layers which . decompose an image into patches of given size | compose these patches into a single image again | . Getting ready . import numpy as np import tensorflow as tf from matplotlib import pyplot as plt from IPython import display image_path = &#39;./images/sunflower.jpg&#39; . Preprocessing the image . Loading the image file into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL Image instance to a Numpy array: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | Converting the single image into a batch. (Keras layers are expecting a batch as input.) . | image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) image_np_array_batch = np.array([image_np_array]) #(3) print(&quot;Image numpy array shape: {}&quot;.format(image_np_array.shape)) . Image numpy array shape: (1080, 1080, 3) . The original image . plt.figure(figsize=(12,12)) plt.title(&#39;Original Image&#39;) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-01T13:50:03.184920 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ The Magic . Time to do the interesting part. In order to decompose an image into patches and also be able to put these patches together into a single image again we create two subclasses of the Keras Layer class. The actual image manipulation is a series of reshape and transpose operation on the input data. . tf.transpose https://www.tensorflow.org/api_docs/python/tf/transpose . | tf.reshape https://www.tensorflow.org/api_docs/python/tf/reshape . | . If you are not familiar with these operation I highly recommend to have a look at the examples given in the documentation linked above and play around with them. . The following implemention of the classes ImageToPatches and PatchesToImage include the possiblity to print out a summary of the shape transitions of the input occuring during a call. Normally debugging during implemention would do the job of course. . In our concrete example, we will get the following shape transitions: . ImageToPatches . (1, 1080, 1080, 3) -&gt; (1, 1080, 2, 540, 3) | (1, 1080, 2, 540, 3) -&gt; (1, 2, 1080, 540, 3) | (1, 2, 1080, 540, 3) -&gt; (4, 540, 540, 3) | PatchesToImage . (4, 540, 540, 3) -&gt; (1, 2, 1080, 540, 3) | (1, 2, 1080, 540, 3) -&gt; (1, 1080, 2, 540, 3) | (1, 1080, 2, 540, 3) -&gt; (1, 1080, 1080, 3) | Later on when we are working with Keras Models the summary method of the Model class will provide this information among other useful data. . class Patchwork(tf.keras.layers.Layer): def __init__(self, image_shape, patch_size): super(Patchwork, self).__init__() self.image_shape = image_shape self.patch_size = patch_size def call(self,input): self.shapes = [] self._store_shape(input) return self.process_input(input) def process_input(self, input): return input def print_transition_summary(self): print(&quot; n{} input shape transitions: n&quot;.format(self.__class__.__name__)) if len(self.shapes) &gt; 1: for i in range(1,len(self.shapes)): print(&quot;{}: {} -&gt; {}&quot;.format(i,self.shapes[i-1],self.shapes[i])) print(&quot; n&quot;) def _store_shape(self,arr): self.shapes.append(arr.shape) class ImageToPatches(Patchwork): def __init__(self, image_shape, patch_size): super(ImageToPatches, self).__init__(image_shape,patch_size) def process_input(self, input): batch_size = tf.shape(input)[0] x = tf.reshape(input, [ batch_size, self.image_shape[0], -1, self.patch_size[1], self.image_shape[2]]) self._store_shape(x) x = tf.transpose(x, [0, 2, 1, 3, 4]) self._store_shape(x) x = tf.reshape(x, [-1, self.patch_size[0], self.patch_size[1], self.image_shape[2]]) self._store_shape(x) return x class PatchesToImage(Patchwork): def __init__(self, image_shape, patch_size): super(PatchesToImage, self).__init__(image_shape,patch_size) self.patch_factor = ( self.image_shape[0]//self.patch_size[0]) * (self.image_shape[1]//self.patch_size[1]) def process_input(self, input): result_batch_size = tf.shape(input)[0] / self.patch_factor x = tf.reshape(input, [ result_batch_size, -1, self.image_shape[0], self.patch_size[1], self.image_shape[2]]) self._store_shape(x) x = tf.transpose(x, [0, 2, 1, 3, 4]) self._store_shape(x) x = tf.reshape( x, [-1, self.image_shape[0], self.image_shape[1], self.image_shape[2]]) self._store_shape(x) return x . Decomposing the image . image_shape = image_np_array.shape patch_size = (image_shape[0]//2,image_shape[1]//2) image_to_patches_layer = ImageToPatches(image_shape,patch_size) patches = image_to_patches_layer(image_np_array_batch) image_to_patches_layer.print_transition_summary() . ImageToPatches input shape transitions: 1: (1, 1080, 1080, 3) -&gt; (1, 1080, 2, 540, 3) 2: (1, 1080, 2, 540, 3) -&gt; (1, 2, 1080, 540, 3) 3: (1, 2, 1080, 540, 3) -&gt; (4, 540, 540, 3) . The glorious result . f, axarr = plt.subplots(2,2) f.set_figheight(12) f.set_figwidth(12) for idx, image_np_array in enumerate(patches): row = idx // 2 col = idx % 2 axarr[col,row].imshow(image_np_array/255.) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-01T13:50:04.299987 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Recomposing the original image from the patch . patches_to_image_layer = PatchesToImage(image_shape,patch_size) recomposed_image = patches_to_image_layer(patches) patches_to_image_layer.print_transition_summary() plt.figure(figsize=(12,12)) plt.title(&#39;Recomposed Image&#39;) plt.imshow(recomposed_image[0]/255.0) plt.show() . PatchesToImage input shape transitions: 1: (4, 540, 540, 3) -&gt; (1, 2, 1080, 540, 3) 2: (1, 2, 1080, 540, 3) -&gt; (1, 1080, 2, 540, 3) 3: (1, 1080, 2, 540, 3) -&gt; (1, 1080, 1080, 3) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-01T13:50:05.194234 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Let&#39;s play . Having the patches of the image at our fingertips, why not trying to be funny by changing the order of the patches before putting them together again. . flipped_patches = np.flip(patches,0) flipped_patches_image = patches_to_image_layer(flipped_patches) plt.figure(figsize=(12,12)) plt.title(&#39;Image with flipped patches&#39;) plt.imshow(flipped_patches_image[0]/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-01T13:50:06.058824 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/",
            "url": "https://dorjeduck.github.io/ai-candies/2020/10/31/patchwork.html",
            "relUrl": "/2020/10/31/patchwork.html",
            "date": " • Oct 31, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Image Flip Layer",
            "content": "Mirror facing mirror - nowhere else. . – Ikkyu . In this tutorial we will create our first custom Keras layer which flips the input images horizontal. . Getting ready . import numpy as np import os import tensorflow as tf from matplotlib import pyplot as plt from IPython import display image_paths = [] image_paths.append(&#39;./images/espresso_1.jpg&#39;) image_paths.append(&#39;./images/espresso_2.jpg&#39;) . Preprocessing the images . Loading the two image files into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL image instances into Numpy arrays: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | image_np_arries = [] for image_path in image_paths: image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) image_np_arries.append(image_np_array) image_np_array_batch = np.array(image_np_arries) . The original images . for idx, image_np_array in enumerate(image_np_array_batch): plt.figure(figsize=(12,12)) plt.title(os.path.basename(image_paths[idx])) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T18:10:43.823761 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T18:10:44.367276 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Our custom Keras layer . For a thorough explanation on custom layers (and models) see: . https://www.tensorflow.org/guide/keras/custom_layers_and_models . class HorizontalFlip(tf.keras.layers.Layer): def __init__(self): super(HorizontalFlip, self).__init__() def call(self, inputs): return tf.image.flip_left_right(inputs) . Flipping the images . horizontal_flip = HorizontalFlip() image_flipped_np_array_batch = horizontal_flip(image_np_array_batch) . The glorious result . for idx, image_np_array in enumerate(image_flipped_np_array_batch): plt.figure(figsize=(12,12)) plt.title(&quot;flipped {}&quot;.format(os.path.basename(image_paths[idx]))) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T18:10:45.822297 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T18:10:46.356201 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/",
            "url": "https://dorjeduck.github.io/ai-candies/2020/10/26/image-flip-layer.html",
            "relUrl": "/2020/10/26/image-flip-layer.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Image cropping",
            "content": "Swim out of your little pond. . – Rumi . In this short tutorial we will see one way of cropping the central portion of two images to a given target height and width with the use of a Keras layer. It is important to notice that the two images have to be of the same height and width in order to be able to crop them togther in one batch. . Getting ready . import numpy as np import os import tensorflow as tf from matplotlib import pyplot as plt from IPython import display target_height = 200 target_width = 800 image_paths = [] image_paths.append(&#39;./images/boot_ganga_1.jpg&#39;) image_paths.append(&#39;./images/boot_ganga_2.jpg&#39;) . Preprocessing the images . Loading the two image files into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL image instancea to Numpy arrays: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | image_np_arries = [] for image_path in image_paths: image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) image_np_arries.append(image_np_array) height, width, _ = image_np_array.shape print(&quot;height/width of {} : {}/{}&quot;.format(os.path.basename(image_path),image_np_array.shape[0],image_np_array.shape[1])) image_np_array_batch = np.array(image_np_arries) . height/width of boot_ganga_1.jpg : 800/1200 height/width of boot_ganga_2.jpg : 800/1200 . The original images . for idx, image_np_array in enumerate(image_np_array_batch): plt.figure(figsize=(12,12)) plt.title(os.path.basename(image_paths[idx])) plt.imshow(image_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:29.613095 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:30.036683 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cropping the images . 1) Creating a CenterCrop layer for given target height and width. https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/CenterCrop . 2) Cropping the images . center_crop_layer = tf.keras.layers.experimental.preprocessing.CenterCrop(target_height,target_width) #(1) image_cropped_np_array_batch = center_crop_layer(image_np_array_batch) #(2) print(&quot;Keras CenterCrop Layer output shape (Numpy Array): {}&quot;.format(image_cropped_np_array_batch.shape)) . Keras CenterCrop Layer output shape (Numpy Array): (2, 200, 800, 3) . The glorious result . for idx, image_cropped_np_array in enumerate(image_cropped_np_array_batch): plt.figure(figsize=(8,8)) plt.title(&quot;resized {}&quot;.format(os.path.basename(image_paths[idx]))) plt.imshow(image_cropped_np_array/255.0) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:31.261107 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:31.435318 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/",
            "url": "https://dorjeduck.github.io/ai-candies/2020/10/26/image-center-crop.html",
            "relUrl": "/2020/10/26/image-center-crop.html",
            "date": " • Oct 26, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Resizing an image with a Keras Layer",
            "content": "Out real nature is infinite in scope. . – Mingyur Rinpoche . First post, everyone welcome. As a start we will use a Keras Layer to resize an image. Sounds doable but do we need a deep learning library like Keras/Tensorflow for that? No. Yet this blog is about learning the building blocks for complex neural networks. . Enjoy . Getting ready . import numpy as np import tensorflow as tf from matplotlib import pyplot as plt from IPython import display image_path = &#39;./images/fujiyama.png&#39; . Preprocessing the image . Loading the image file into PIL format: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img . | Converting the PIL Image instance to a Numpy array: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/img_to_array . | Determining the height and width of the image. . | Converting the single image into a batch. (Keras layers are expecting a batch as input.) . | image_pil = tf.keras.preprocessing.image.load_img(image_path) #(1) image_np_array = tf.keras.preprocessing.image.img_to_array(image_pil) #(2) height,width,_ = image_np_array.shape #(3) image_np_array_batch = np.array([image_np_array]) #(4) print(&quot;Image numpy array shape: {}&quot;.format(image_np_array.shape)) . Image numpy array shape: (1024, 1536, 3) . The original image . plt.figure(figsize=(12,12)) plt.title(&#39;Original Image&#39;) plt.imshow(image_np_array/255.0) plt.show() print(&quot; nImage height/width: {}/{} n&quot;.format(height,width)) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:54.511012 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Image height/width: 1024/1536 . Resizing the image . 1) Creating an Image resizing layer for given target height &amp; width with Keras https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Resizing . 2) Resizing the image . height_resized = height // 2 width_resized = width // 2 print(&quot;Desired target image height/width: {}/{}&quot;.format(height_resized,width_resized)) resize_layer = tf.keras.layers.experimental.preprocessing.Resizing(height_resized,width_resized,interpolation=&#39;bilinear&#39;) #(1) image_resized_np_array_batch = resize_layer(image_np_array_batch) #(2) print(&quot;Keras Resizing Layer output shape (Numpy Array): {}&quot;.format(image_resized_np_array_batch.shape)) . Desired target image height/width: 512/768 Keras Resizing Layer output shape (Numpy Array): (1, 512, 768, 3) . The glorious result . image_resized_np_array = image_resized_np_array_batch[0] height_resized,width_resized,_ = image_resized_np_array.shape plt.figure(figsize=(6,6)) plt.title(&#39;Resized Image&#39;) plt.imshow(image_resized_np_array/255.0) plt.show() print(&quot; nResized image height/width: {}/{} n&quot;.format(height_resized,width_resized)) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-10-31T17:31:55.248885 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Resized image height/width: 512/768 .",
            "url": "https://dorjeduck.github.io/ai-candies/2020/10/25/image-resizing.html",
            "relUrl": "/2020/10/25/image-resizing.html",
            "date": " • Oct 25, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Hello visual world",
          "content": "I study my mind and therefore all appearances are my texts. . – Milarepa . This blog is driven by the idea to teach myself how to process and generate images with Tensorflow. The initial posts will mostly cover basic techniques which hopefully come in handy years later when I start trying to impress myself with more complex models based on these earlier insights. . Please feel invited to come along with me on this journey. I will try to include links to the respective parts of the excellent Tensorflow documentation or other gems on the web as much as possible in order to make this whole endeavour at least of some benefit. . As always, feedback and suggestions of any kind are highly appreciated. .",
          "url": "https://dorjeduck.github.io/ai-candies/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://dorjeduck.github.io/ai-candies/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}